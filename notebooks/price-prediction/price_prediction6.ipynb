{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de3e4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 기본 설정 및 라이브러리 임포트 ---\n",
    "\n",
    "# 데이터 분석 및 처리를 위한 필수 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os, sys\n",
    "from datetime import datetime\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from scipy import stats\n",
    "from IPython.display import display\n",
    "\n",
    "# 모델링 및 기계 학습을 위한 라이브러리\n",
    "import lightgbm as lgb                              # LightGBM 모델\n",
    "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit # 교차 검증을 위한 K-폴드 및 시계열 분할\n",
    "from sklearn.preprocessing import LabelEncoder      # 범주형 데이터 인코딩\n",
    "from sklearn.metrics import mean_squared_error      # 평가 지표 (RMSE 계산용)\n",
    "from sklearn.cluster import KMeans                  # K-평균 군집화\n",
    "from sklearn.preprocessing import StandardScaler    # 데이터 스케일링\n",
    "\n",
    "# 하이퍼파라미터 최적화를 위한 라이브러리\n",
    "import optuna\n",
    "\n",
    "# 기타 유틸리티\n",
    "import gc                                           # 가비지 컬렉션 (메모리 관리)\n",
    "from tqdm import tqdm                               # 작업 진행률 표시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')                   # 불필요한 경고 메시지 무시\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import matplotlib.font_manager as fm\n",
    "try:\n",
    "    # 나눔고딕 폰트 경로 설정 (경로는 환경에 따라 조정 필요)\n",
    "    font_path = '../../font/NanumFont/NanumGothic.ttf'\n",
    "    \n",
    "    # 폰트가 존재하는지 확인 후 설정\n",
    "    if os.path.exists(font_path):\n",
    "        fe = fm.FontEntry(fname=font_path, name='NanumGothic')\n",
    "        fm.fontManager.ttflist.insert(0, fe)\n",
    "        plt.rcParams.update({'font.size': 12, 'font.family': 'NanumGothic'})\n",
    "    else:\n",
    "        print(\"나눔고딕 폰트를 찾을 수 없어 기본 폰트로 설정됩니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"폰트 설정 중 오류 발생: {e}\")\n",
    "    pass\n",
    "\n",
    "\n",
    "# 로거(실행 기록 로그 저장) 임포트\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"../../src/log\"))\n",
    "sys.path.insert(0, src_path)\n",
    "from logger import Logger\n",
    "print(\"Logger 모듈 로드 성공.\")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "LOG_DIR = '../../data/logs/price_prediction_6_logs'\n",
    "LOG_FILENAME = f\"price_prediction_{timestamp}.log\"\n",
    "LOG_PATH = os.path.join(LOG_DIR, LOG_FILENAME)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "logger = Logger(log_path=LOG_PATH)\n",
    "\n",
    "\n",
    "# 데이터 경로 설정\n",
    "RAW_DIR             = '../../data/processed/clean_data'                 # 원본 데이터 디렉토리\n",
    "TRAIN_FILENAME      = 'train.csv'                                       # 훈련 데이터 파일명\n",
    "TEST_FILENAME       = 'test.csv'                                        # 테스트 데이터 파일명\n",
    "TRAIN_PATH          = os.path.join(RAW_DIR, TRAIN_FILENAME)             # 훈련 데이터 경로\n",
    "TEST_PATH           = os.path.join(RAW_DIR, TEST_FILENAME)              # 테스트 데이터 경로\n",
    "SUBMISSION_DIR      = '../../data/processed/submissions'                # 제출 파일 디렉토리\n",
    "SUBMISSION_FILENAME = 'price_prediction_6_submission.csv'               # 제출 파일명\n",
    "SUBMISSION_PATH     = os.path.join(SUBMISSION_DIR, SUBMISSION_FILENAME) # 제출 파일 경로\n",
    "MODEL_DIR           = '../../model'                                     # 모델 저장 디렉토리\n",
    "MODEL_FILENAME      = 'price_prediction_6_model.pkl'                    # 모델 파일명\n",
    "MODEL_PATH          = os.path.join(MODEL_DIR, MODEL_FILENAME)           # 모델 경로\n",
    "\n",
    "# 결과 저장 디렉토리 생성\n",
    "os.makedirs(SUBMISSION_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "logger.start_redirect()\n",
    "logger.write(\"=\"*50)\n",
    "logger.write(\">> < 아파트 가격 예측 모델링 시작 >\\n\\n\")\n",
    "logger.write(\">> [1단계 완료] 라이브러리, 경로, 로거 초기화 성공!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2b03e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 데이터 로드 및 초기 전처리 (수정 완료) ---\n",
    "try:\n",
    "    logger.write(\">> [2단계 시작] 데이터 로드를 시작합니다...\")\n",
    "    \n",
    "    # CSV 파일로부터 훈련 및 테스트 데이터를 로드합니다.\n",
    "    train_df = pd.read_csv(TRAIN_PATH)\n",
    "    test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "    # 훈련 데이터와 테스트 데이터를 하나로 합칩니다.\n",
    "    df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "    logger.write(\">> 데이터 로드 및 병합 완료.\")\n",
    "    \n",
    "    # TimeSeriesSplit을 위해 '계약일자' 컬럼만으로 시간순 정렬합니다.\n",
    "    df = df.sort_values(by=['계약일자']).reset_index(drop=True)\n",
    "    logger.write(\">> TimeSeriesSplit을 위해 데이터를 시간순으로 정렬했습니다.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 2단계 데이터 로드 및 전처리 중 문제 발생: {e}\", print_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb19e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 피처 엔지니어링 (Feature Engineering) ---\n",
    "# 기존 데이터를 바탕으로 모델 성능을 높일 새로운 특성을 생성합니다.\n",
    "\n",
    "try:\n",
    "    logger.write(\">> [3단계 시작] 피처 엔지니어링을 시작합니다...\")\n",
    "    \n",
    "    # '계약년월'을 '계약년'과 '계약월'로 분리합니다.\n",
    "    df['계약년'] = df['계약년월'].astype(str).str[:4].astype(int)\n",
    "    df['계약월'] = df['계약년월'].astype(str).str[4:].astype(int)\n",
    "    \n",
    "    # 건물의 나이(연식)을 계산합니다.\n",
    "    df['건물나이'] = df['계약년'] - df['연식']\n",
    "    \n",
    "    # 거래 시점(연도와 월의 조합)을 나타내는 특성을 생성합니다.\n",
    "    df['거래시점'] = (df['계약년'] - 2007) * 12 + df['계약월']\n",
    "    \n",
    "    # --- K-평균 군집화 (K-Means Clustering) ---\n",
    "    try:\n",
    "        logger.write(\">> K-평균 군집화를 시작합니다...\")\n",
    "        cluster_cols = ['좌표X', '좌표Y', '건물나이', '전용면적', '층']\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df[cluster_cols])\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=10, random_state=42, n_init=10)\n",
    "        df['아파트군집'] = kmeans.fit_predict(df_scaled)\n",
    "        \n",
    "        logger.write(f\">> K-평균 군집화 완료. '{len(cluster_cols)}'개 특성을 사용해 10개의 '아파트군집' 생성.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.write(f\">> [오류] K-평균 군집화 중 문제 발생: {e}\", print_error=True)\n",
    "    \n",
    "    # --- 고급 피처 엔지니어링 ---\n",
    "    logger.write(\">> 고급 피처 엔지니어링을 시작합니다...\")\n",
    "\n",
    "    # 계약월의 주기성을 나타내는 sin/cos 변환 피처 생성\n",
    "    df['계약월_sin'] = np.sin(2 * np.pi * df['계약월']/12)\n",
    "    df['계약월_cos'] = np.cos(2 * np.pi * df['계약월']/12)\n",
    "    logger.write(\">> 1. 시간 관련(sin/cos) 피처 생성 완료.\")\n",
    "    \n",
    "    # 교통 편의성 가중합 특성\n",
    "    df['가중지하철'] = df['반경_1km_지하철역_수'] * 1.0 + df['반경_500m_지하철역_수'] * 1.5 + df['반경_300m_지하철역_수'] * 2.0\n",
    "    df['가중버스'] = df['반경_1km_버스정류장_수'] * 1.0 + df['반경_500m_버스정류장_수'] * 1.5 + df['반경_300m_버스정류장_수'] * 2.0\n",
    "    logger.write(\">> 2. 교통 관련 가중합 특성 생성 완료.\")\n",
    "\n",
    "    # 면적당 가격 기반 통계 피처 생성\n",
    "    train_df_temp = df[df['target'].notna()].copy()\n",
    "    train_df_temp['면적당가격'] = np.log1p(train_df_temp['target']) / train_df_temp['전용면적']\n",
    "\n",
    "    # --- [핵심 수정] Named Aggregation을 사용하여 중복 컬럼 문제 해결 ---\n",
    "    # 법정동 및 자치구별 면적당 가격의 평균과 표준편차 계산\n",
    "    dong_price_stats = train_df_temp.groupby('법정동').agg(\n",
    "        동별_평균면적당가격=('면적당가격', 'mean'),\n",
    "        동별_면적당가격편차=('면적당가격', 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    gu_price_stats = train_df_temp.groupby('자치구').agg(\n",
    "        구별_평균면적당가격=('면적당가격', 'mean'),\n",
    "        구별_면적당가격편차=('면적당가격', 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # 전체 데이터프레임에 통계 피처 병합\n",
    "    df = pd.merge(df, dong_price_stats, on='법정동', how='left')\n",
    "    df = pd.merge(df, gu_price_stats, on='자치구', how='left')\n",
    "    logger.write(\">> 3. 면적당 가격 관련 통계 피처 생성 및 병합 완료.\")\n",
    "\n",
    "    # 상호작용 특성 생성\n",
    "    df['면적_x_나이'] = df['전용면적'] * df['건물나이']\n",
    "    df['면적_x_층'] = df['전용면적'] * df['층']\n",
    "    df['강남_x_면적'] = df['강남3구여부'] * df['전용면적']\n",
    "    logger.write(\">> 4. 상호작용 특성 생성 완료.\")\n",
    "\n",
    "    # 생성된 통계 피처의 결측치 처리\n",
    "    fill_na_cols = ['동별_평균면적당가격', '동별_면적당가격편차', '구별_평균면적당가격', '구별_면적당가격편차']\n",
    "    \n",
    "    # df에 실제로 존재하는 통계 컬럼만 선택하여 결측치를 채웁니다.\n",
    "    existing_cols = [col for col in fill_na_cols if col in df.columns]\n",
    "    \n",
    "    if existing_cols:\n",
    "        # 훈련 데이터(train_df_temp)의 평균으로만 결측치를 채워 데이터 유출을 방지합니다.\n",
    "        mean_vals = train_df_temp[existing_cols].mean()\n",
    "        df[existing_cols] = df[existing_cols].fillna(mean_vals)\n",
    "        logger.write(\">> 5. 통계 피처 결측치 처리 완료.\")\n",
    "    else:\n",
    "        logger.write(\">> 5. 생성된 통계 피처에 결측치가 없어 처리를 건너뜁니다.\")\n",
    "\n",
    "    logger.write(\">> 고급 피처 엔지니어링 완료.\")\n",
    "    \n",
    "    logger.write(\">> [3단계 완료] 피처 엔지니어링 성공.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 3단계 피처 엔지니어링 중 문제 발생: {e}\", print_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fac234f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. 데이터 스케일링 및 인코딩 ---\n",
    "\n",
    "try:\n",
    "    logger.write(\">> [4단계 시작] 데이터 스케일링 및 인코딩을 시작합니다...\")\n",
    "\n",
    "    # --- 로그 변환 (Log Transformation) ---\n",
    "    # 타겟 변수인 'target'(실거래가)의 분포를 정규분포에 가깝게 만들어 모델 성능을 안정시킵니다.\n",
    "    # np.log1p는 np.log(x + 1)과 같으며, 0 또는 매우 작은 값에 대한 로그 계산 시 발생할 수 있는 오류를 방지합니다.\n",
    "    df['target'] = np.log1p(df['target'])\n",
    "    logger.write(\">> 타겟 변수(target) 로그 변환 완료.\")\n",
    "\n",
    "    # --- 라벨 인코딩 (Label Encoding) ---\n",
    "    # '아파트명', '도로명', '법정동'과 같은 문자열(범주형) 데이터를 모델이 이해할 수 있는 숫자형 데이터로 변환합니다.\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    logger.write(\">> 범주형 데이터 라벨 인코딩 완료.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 4단계 스케일링 및 인코딩 중 문제 발생: {e}\", print_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b513f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. 최종 데이터 준비 ---\n",
    "# 전처리와 피처 엔지니어링이 완료된 데이터를 다시 훈련 세트와 테스트 세트로 분리합니다.\n",
    "\n",
    "try:\n",
    "    logger.write(\">> [5단계 시작] 최종 데이터 분리를 시작합니다...\")\n",
    "    \n",
    "    # 'target' 컬럼의 결측치 여부를 기준으로 훈련 데이터와 테스트 데이터를 나눕니다.\n",
    "    train_df = df[df['target'].notna()]\n",
    "    test_df = df[df['target'].isna()]\n",
    "    \n",
    "    # 테스트 데이터에서는 더 이상 필요 없는 'target' 컬럼을 제거합니다.\n",
    "    test_df = test_df.drop('target', axis=1)\n",
    "\n",
    "    # 모델의 입력(X)과 타겟(y)을 정의합니다.\n",
    "    # 'target'과 날짜 관련 컬럼은 입력에서 제외합니다.\n",
    "    X_train = train_df.drop(['target', '계약년월'], axis=1)\n",
    "    y_train = train_df['target']\n",
    "    X_test = test_df.drop(['계약년월'], axis=1)\n",
    "    \n",
    "    logger.write(f\">> 최종 데이터 분리 완료. 훈련 데이터: {X_train.shape}, 테스트 데이터: {X_test.shape}\")\n",
    "    logger.write(\">> [5단계 완료] 최종 데이터 준비 성공.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 5단계 최종 데이터 준비 중 문제 발생: {e}\", print_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45a76a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 특성 선택 (Feature Selection) ---\n",
    "# LightGBM 모델을 한 번 실행하여 모델 성능에 중요하게 기여하는 특성들을 선별합니다.\n",
    "\n",
    "try:\n",
    "    logger.write(\">> [6단계 시작] 특성 선택을 시작합니다...\")\n",
    "    \n",
    "    # 임시 LightGBM 모델을 훈련하여 특성 중요도를 계산합니다.\n",
    "    temp_model = lgb.LGBMRegressor(random_state=42)\n",
    "    temp_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 특성 중요도가 0 이상인, 즉 모델이 한 번이라도 사용한 특성들만 선택합니다.\n",
    "    feature_importances = pd.Series(temp_model.feature_importances_, index=X_train.columns)\n",
    "    selected_features = feature_importances[feature_importances > 0].index.tolist()\n",
    "    \n",
    "    # 선택된 특성들만 사용하여 훈련 및 테스트 데이터를 다시 구성합니다.\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "    \n",
    "    logger.write(f\">> 특성 선택 완료. 총 {len(X_train.columns)}개 중 {len(selected_features)}개 선택됨.\")\n",
    "    logger.write(\">> [6단계 완료] 특성 선택 성공.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 6단계 특성 선택 중 문제 발생: {e}\", print_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc335b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. 하이퍼파라미터 최적화 (Optuna) ---\n",
    "# 모델의 성능을 극대화하기 위해 최적의 하이퍼파라미터 조합을 탐색합니다.\n",
    "\n",
    "try:\n",
    "    # Optuna가 최적의 하이퍼파라미터를 찾기 위해 반복적으로 실행하는 함수(objective)를 정의합니다.\n",
    "    def objective(trial, X, y):\n",
    "        # 테스트할 하이퍼파라미터의 범위를 정의합니다.\n",
    "        param = {\n",
    "            'objective': 'regression_l1', 'metric': 'rmse',\n",
    "            'n_estimators': 2000, \n",
    "            'verbosity': -1, 'boosting_type': 'gbdt', 'seed': 42,\n",
    "            'device': 'cuda', 'n_jobs': -1,\n",
    "            \n",
    "            # Optuna의 trial 객체를 통해 탐색할 파라미터 값의 범위를 제안받습니다.\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 30, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 7, 25),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 1e-5, 10.0, log=True),\n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', 1e-5, 10.0, log=True),\n",
    "        }\n",
    "\n",
    "        # TimeSeriesSplit 교차 검증을 적용합니다.\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        rmse_scores = []\n",
    "        \n",
    "        # --- for 반복문 내부에 실제 실행 코드 추가 ---\n",
    "        for train_idx, val_idx in tscv.split(X):\n",
    "            # 1. 데이터를 훈련 및 검증 세트로 분리합니다.\n",
    "            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            # 2. 모델을 생성하고 훈련합니다.\n",
    "            model = lgb.LGBMRegressor(**param)\n",
    "            model.fit(X_train_fold, y_train_fold,\n",
    "                      eval_set=[(X_val_fold, y_val_fold)],\n",
    "                      eval_metric='rmse',\n",
    "                      callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "            \n",
    "            # 3. 검증 세트로 예측 후 RMSE를 계산하여 리스트에 추가합니다.\n",
    "            val_preds = model.predict(X_val_fold)\n",
    "            rmse = np.sqrt(mean_squared_error(y_val_fold, val_preds))\n",
    "            rmse_scores.append(rmse)\n",
    "        \n",
    "        # 5개 구간에서 얻은 RMSE 점수의 평균을 반환합니다.\n",
    "        return np.mean(rmse_scores)\n",
    "\n",
    "    # Optuna 최적화를 실행합니다.\n",
    "    if 'X_train_selected' in locals():\n",
    "        logger.write(\">> [7단계 시작] Optuna와 TimeSeriesSplit으로 하이퍼파라미터 최적화를 시작합니다...\")\n",
    "        \n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective(trial, X_train_selected, y_train), n_trials=50)\n",
    "        \n",
    "        # 탐색을 통해 찾은 최적의 파라미터를 저장합니다.\n",
    "        best_params = study.best_params\n",
    "        best_params.update({\n",
    "            'objective': 'regression_l1', 'metric': 'rmse', 'n_estimators': 2000,\n",
    "            'verbosity': -1, 'seed': 42, 'device': 'cuda'\n",
    "        })\n",
    "        \n",
    "        logger.write(f\">> Optuna 탐색 완료. 최적 파라미터: {best_params}\")\n",
    "        logger.write(\">> [7단계 완료] 하이퍼파라미터 최적화 성공.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 7단계 하이퍼파라미터 최적화 중 문제 발생: {e}\", print_error=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d824617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. 최종 모델 훈련 및 예측 ---\n",
    "# Optuna를 통해 찾은 최적의 하이퍼파라미터로 최종 모델을 훈련하고, 테스트 데이터에 대한 예측을 수행합니다.\n",
    "\n",
    "try:\n",
    "    if 'best_params' in locals():\n",
    "        logger.write(\">> [8단계 시작] 최종 모델 훈련 및 예측을 시작합니다...\")\n",
    "        \n",
    "        # 최종 LightGBM 모델을 최적의 파라미터로 초기화합니다.\n",
    "        final_model = lgb.LGBMRegressor(**best_params)\n",
    "        \n",
    "        # 선택된 특성으로 구성된 전체 훈련 데이터를 사용하여 모델을 훈련합니다.\n",
    "        final_model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # 테스트 데이터에 대한 예측을 수행합니다.\n",
    "        predictions = final_model.predict(X_test_selected)\n",
    "        \n",
    "        # [중요] 로그 변환되었던 예측값을 원래의 가격 스케일로 되돌립니다.\n",
    "        # np.expm1은 np.exp(x) - 1과 같으며, np.log1p의 역함수 관계입니다.\n",
    "        predictions = np.expm1(predictions)\n",
    "        \n",
    "        logger.write(\">> [8단계 완료] 최종 모델 훈련 및 예측 성공.\")\n",
    "    else:\n",
    "        logger.write(\">> [알림] 7단계 하이퍼파라미터 최적화가 실행되지 않아 8단계를 건너뜁니다.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 8단계 최종 모델 훈련 및 예측 중 문제 발생: {e}\", print_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f97dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. 제출 파일 생성 ---\n",
    "# 예측 결과를 경진대회 제출 형식에 맞게 CSV 파일로 저장합니다.\n",
    "\n",
    "try:\n",
    "    if 'predictions' in locals():\n",
    "        logger.write(\">> [9단계 시작] 제출 파일 생성을 시작합니다...\")\n",
    "        \n",
    "        # 모델 저장\n",
    "        joblib.dump(final_model, MODEL_PATH)\n",
    "        logger.write(f\">> 모델 저장 완료: {MODEL_PATH}\")\n",
    "        \n",
    "        logger.write(\">> 'target' 컬럼만 포함된 제출 파일을 생성합니다.\")\n",
    "        # 제출용 샘플 파일의 'target' 컬럼에 예측값을 채워 넣습니다.\n",
    "        submission_df['target'] = predictions\n",
    "        submission_df['target'] = submission_df['target'].astype(int)\n",
    "        \n",
    "        # 'submission.csv' 파일로 저장합니다. 인덱스는 저장하지 않습니다.\n",
    "        submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "        logger.write(f\">> 제출 파일 생성 완료: {SUBMISSION_PATH}\")\n",
    "        \n",
    "        logger.write(\">> [9단계 완료] 제출 파일 생성 성공. 'submission.csv' 파일을 확인하세요.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 9단계 제출 파일 생성 중 문제 발생: {e}\", print_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. 최종 모델 검증 및 시각화 ---\n",
    "# 모델의 성능을 다각도로 분석하고, 예측의 근거를 확인합니다.\n",
    "\n",
    "try:\n",
    "    if 'final_model' in locals():\n",
    "        logger.write(\">> [10단계 시작] 최종 모델 검증 및 시각화를 시작합니다...\")\n",
    "\n",
    "        # --- 1. OOF 예측 생성 및 CV 점수 확보 (신뢰도 높은 분석을 위함) ---\n",
    "        logger.write(\">> 1. OOF(Out-of-Fold) 예측값 및 CV 점수를 생성합니다...\")\n",
    "        \n",
    "        # TimeSeriesSplit 설정\n",
    "        tscv = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        oof_preds = np.zeros(X_train_selected.shape[0]) # OOF 예측을 저장할 배열\n",
    "        cv_rmse_scores = [] # 각 Fold의 RMSE 점수를 저장할 리스트\n",
    "\n",
    "        # 교차 검증을 다시 수행하여 OOF 예측 생성\n",
    "        for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train_selected)):\n",
    "            X_train_fold, X_val_fold = X_train_selected.iloc[train_idx], X_train_selected.iloc[val_idx]\n",
    "            y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            # best_params로 모델을 다시 훈련\n",
    "            model = lgb.LGBMRegressor(**best_params)\n",
    "            model.fit(X_train_fold, y_train_fold,\n",
    "                      eval_set=[(X_val_fold, y_val_fold)],\n",
    "                      eval_metric='rmse',\n",
    "                      callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "            \n",
    "            # 검증 세트(Validation Set)에 대한 예측값을 OOF 배열의 해당 위치에 저장\n",
    "            val_preds = model.predict(X_val_fold)\n",
    "            oof_preds[val_idx] = val_preds\n",
    "            \n",
    "            # 현재 Fold의 RMSE 점수 계산 및 저장\n",
    "            rmse = np.sqrt(mean_squared_error(y_val_fold, val_preds))\n",
    "            cv_rmse_scores.append(rmse)\n",
    "            logger.write(f\">> Fold {fold+1} RMSE: {rmse:.4f}\")\n",
    "\n",
    "        logger.write(f\">> 최종 CV 평균 RMSE: {np.mean(cv_rmse_scores):.4f}\")\n",
    "        \n",
    "        # --- 2. 피처 중요도(Feature Importance) 시각화 ---\n",
    "        logger.write(\"\\n>> 2. 피처 중요도를 시각화합니다...\")\n",
    "        feature_importances = pd.DataFrame(\n",
    "            {'feature': X_train_selected.columns, 'importance': final_model.feature_importances_}\n",
    "        ).sort_values('importance', ascending=False)\n",
    "\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.barplot(x='importance', y='feature', data=feature_importances.head(20))\n",
    "        plt.title('상위 20개 피처 중요도 (Feature Importance)', fontsize=16)\n",
    "        plt.xlabel('중요도', fontsize=12)\n",
    "        plt.ylabel('피처', fontsize=12)\n",
    "        plt.grid(True, axis='x', linestyle='--')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- 3. 실제 값 vs OOF 예측 값 비교 (Scatter Plot) ---\n",
    "        logger.write(\"\\n>> 3. 실제 값과 OOF 예측 값을 비교합니다...\")\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.scatterplot(x=y_train, y=oof_preds, alpha=0.3)\n",
    "        plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2, label='이상적인 예측선 (y=x)')\n",
    "        plt.title('실제 값 vs OOF 예측 값 비교', fontsize=16)\n",
    "        plt.xlabel('실제 값 (Actual)', fontsize=12)\n",
    "        plt.ylabel('OOF 예측 값 (Predicted)', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- 4. 잔차(Residuals) 분석 ---\n",
    "        logger.write(\"\\n>> 4. 잔차(실제-예측)를 분석합니다...\")\n",
    "        residuals = y_train - oof_preds\n",
    "        \n",
    "        # 잔차 분포 (Histogram)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(residuals, kde=True, bins=50)\n",
    "        plt.title('잔차 분포 (OOF)', fontsize=16)\n",
    "        plt.xlabel('잔차 (Residuals)', fontsize=12)\n",
    "        plt.ylabel('빈도 (Frequency)', fontsize=12)\n",
    "        plt.axvline(x=0, color='red', linestyle='--')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 잔차 vs 예측 값 (Scatter Plot)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=oof_preds, y=residuals, alpha=0.3)\n",
    "        plt.axhline(y=0, color='red', linestyle='--')\n",
    "        plt.title('잔차 vs OOF 예측 값', fontsize=16)\n",
    "        plt.xlabel('OOF 예측 값 (Predicted)', fontsize=12)\n",
    "        plt.ylabel('잔차 (Residuals)', fontsize=12)\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- 5. 교차 검증(CV) 폴드별 RMSE 점수 시각화 ---\n",
    "        logger.write(\"\\n>> 5. 교차 검증 폴드별 RMSE 점수를 시각화합니다...\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=[f'Fold {i+1}' for i in range(len(cv_rmse_scores))], y=cv_rmse_scores)\n",
    "        plt.title('TimeSeriesSplit 교차 검증 RMSE 점수', fontsize=16)\n",
    "        plt.xlabel('폴드 (Fold)', fontsize=12)\n",
    "        plt.ylabel('RMSE', fontsize=12)\n",
    "        plt.axhline(y=np.mean(cv_rmse_scores), color='r', linestyle='--', label=f'평균 RMSE: {np.mean(cv_rmse_scores):.4f}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, axis='y')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- 6. 학습 데이터와 테스트 예측 결과 분포 비교 (KDE Plot) ---\n",
    "        logger.write(\"\\n>> 6. 학습 데이터와 테스트 예측의 분포를 비교합니다...\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # 로그 변환된 값으로 비교해야 스케일이 맞음\n",
    "        sns.kdeplot(y_train, label='학습 데이터 실제 값 (Log)', color='blue', fill=True)\n",
    "        sns.kdeplot(np.log1p(predictions), label='테스트 데이터 예측 값 (Log)', color='orange', fill=True)\n",
    "        plt.title('학습 데이터와 테스트 예측의 분포 비교 (Log Scale)', fontsize=16)\n",
    "        plt.xlabel('아파트 가격 (Log Transformed)', fontsize=12)\n",
    "        plt.ylabel('밀도 (Density)', fontsize=12)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # --- 7. SHAP (SHapley Additive exPlanations) 분석 ---\n",
    "        logger.write(\"\\n>> 7. SHAP 분석을 시작합니다 (계산에 시간이 다소 소요될 수 있습니다)...\")\n",
    "        try:\n",
    "            explainer = shap.TreeExplainer(final_model)\n",
    "            # 데이터가 너무 크면 샘플링하여 사용 (1000개 샘플)\n",
    "            shap_sample = X_train_selected.sample(1000, random_state=42)\n",
    "            shap_values = explainer.shap_values(shap_sample)\n",
    "\n",
    "            # SHAP 요약 플롯 (Summary Plot)\n",
    "            logger.write(\">> SHAP 요약 플롯: 각 피처가 예측에 미치는 영향을 종합적으로 보여줍니다.\")\n",
    "            shap.summary_plot(shap_values, shap_sample, plot_type=\"dot\")\n",
    "\n",
    "            # SHAP 의존성 플롯 (Dependence Plot)\n",
    "            logger.write(\"\\n>> SHAP 의존성 플롯: '전용면적'이 예측 가격에 미치는 영향을 보여줍니다.\")\n",
    "            shap.dependence_plot('전용면적', shap_values, shap_sample, interaction_index=\"건물나이\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.write(f\">> [오류] SHAP 분석 중 문제가 발생했습니다: {e}\", print_error=True)\n",
    "\n",
    "        logger.write(\"\\n>> [10단계 완료] 모델 분석 및 시각화 성공.\")\n",
    "\n",
    "    else:\n",
    "        logger.write(\">> [알림] 최종 모델이 생성되지 않아 10단계 시각화를 건너뜁니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.write(f\">> [오류] 10단계 모델 분석 및 시각화 중 문제 발생: {e}\", print_error=True)\n",
    "    \n",
    "# finally:\n",
    "#         logger.stop_redirect()\n",
    "#         logger.write(\">> 모델링 종료\")\n",
    "#         logger.write(\"=\"*50 + \"\\n\")\n",
    "#         logger.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "house_price_predict_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
