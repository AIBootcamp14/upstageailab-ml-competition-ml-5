{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('data/processed/cleaned_data/train_clean.csv')\n",
    "test = pd.read_csv('data/processed/cleaned_data/test_clean.csv')\n",
    "\n",
    "# EDA: target 분포 확인\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(train['target'], bins=50, kde=True)\n",
    "plt.title('Target 분포')\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# EDA: 주요 피처 분포 확인\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x=train['전용면적'])\n",
    "plt.title('전용면적 분포')\n",
    "plt.show()\n",
    "\n",
    "# EDA: 상관관계 히트맵\n",
    "corr = train.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\")\n",
    "plt.title('상관관계 히트맵')\n",
    "plt.show()\n",
    "\n",
    "# EDA: 산점도 (전용면적 vs target)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x='전용면적', y='target', data=train)\n",
    "plt.title('전용면적 vs Target')\n",
    "plt.show()\n",
    "\n",
    "# 파생 변수 생성: 계약일자 -> 년, 월, 분기\n",
    "train['계약일자'] = pd.to_datetime(train['계약일자'], format='%Y%m%d')\n",
    "train['계약년'] = train['계약일자'].dt.year\n",
    "train['계약월'] = train['계약일자'].dt.month\n",
    "train['계약분기'] = train['계약일자'].dt.quarter\n",
    "\n",
    "# 파생 변수 생성: 연식 기준 신축여부\n",
    "train['신축여부'] = train['연식'].apply(lambda x: 1 if x <= 5 else 0)\n",
    "\n",
    "# 파생 변수 생성: 구 이름 추출\n",
    "train['구'] = train['자치구'].str.split().str[1]\n",
    "\n",
    "# test 데이터에도 동일 파생 변수 적용\n",
    "test['계약일자'] = pd.to_datetime(test['계약일자'], format='%Y%m%d')\n",
    "test['계약년'] = test['계약일자'].dt.year\n",
    "test['계약월'] = test['계약일자'].dt.month\n",
    "test['계약분기'] = test['계약일자'].dt.quarter\n",
    "\n",
    "test['신축여부'] = test['연식'].apply(lambda x: 1 if x <= 5 else 0)\n",
    "\n",
    "test['구'] = test['자치구'].str.split().str[1]\n",
    "\n",
    "# 모델 입력 변수 설정\n",
    "feature_cols = [\n",
    "    '전용면적', '연식', '강남3구여부', '구', '계약년', '계약월', '계약분기', '신축여부',\n",
    "    '반경_1km_지하철역_수', '반경_500m_지하철역_수', '반경_300m_지하철역_수',\n",
    "    '반경_1km_버스정류장_수', '반경_500m_버스정류장_수', '반경_300m_버스정류장_수',\n",
    "    '총인구수', '성비(남/여)', 'loanrate_1m', 'loanrate_3m', 'loanrate_6m', 'loanrate_12m'\n",
    "]\n",
    "X = train[feature_cols]\n",
    "y = train['target']\n",
    "\n",
    "# 학습/검증 데이터 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 전처리 파이프라인 정의\n",
    "numeric_features = [\n",
    "    '전용면적', '연식', '강남3구여부', '계약년', '계약월', '계약분기', '신축여부',\n",
    "    '반경_1km_지하철역_수', '반경_500m_지하철역_수', '반경_300m_지하철역_수',\n",
    "    '반경_1km_버스정류장_수', '반경_500m_버스정류장_수', '반경_300m_버스정류장_수',\n",
    "    '총인구수', '성비(남/여)', 'loanrate_1m', 'loanrate_3m', 'loanrate_6m', 'loanrate_12m'\n",
    "]\n",
    "categorical_features = ['구']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "categorical_transformer = Pipeline(steps=[('ohe', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 파이프라인 구성 (전처리 + LightGBM)\n",
    "model = lgb.LGBMRegressor(random_state=42)\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "\n",
    "# 하이퍼파라미터 탐색 설정\n",
    "param_dist = {\n",
    "    'model__num_leaves': [31, 50, 70],\n",
    "    'model__learning_rate': [0.1, 0.01, 0.001],\n",
    "    'model__max_depth': [-1, 10, 20]\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "# 최적 모델로 검증 데이터 예측 및 평가\n",
    "best_model = search.best_estimator_\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(f\"MAE: {mae:.2f}, R2: {r2:.3f}\")\n",
    "\n",
    "# 잔차 분석: 분포 & 산점도\n",
    "residuals = y_val - y_pred\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Residuals Distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_val, y_pred)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# 피처 중요도 시각화\n",
    "importances = best_model.named_steps['model'].feature_importances_\n",
    "# OHE 후 컬럼 이름 생성\n",
    "ohe_features = best_model.named_steps['preprocessor'] \\\n",
    "    .transformers_[1][1] \\\n",
    "    .named_steps['ohe'] \\\n",
    "    .get_feature_names_out(categorical_features)\n",
    "feature_names = numeric_features + list(ohe_features)\n",
    "fi = pd.Series(importances, index=feature_names).sort_values()  \n",
    "plt.figure(figsize=(10,8))\n",
    "fi.plot.barh()\n",
    "plt.title('Feature Importances')\n",
    "plt.show()\n",
    "\n",
    "# 모델 저장\n",
    "date_str = pd.Timestamp.now().strftime('%Y%m%d')\n",
    "joblib.dump(best_model, f'lgbm_price_model_{date_str}.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
