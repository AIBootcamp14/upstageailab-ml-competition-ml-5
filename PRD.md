## **서울시 아파트 실거래가 예측 모델 개발 PRD**

### **1. 프로젝트 개요 (Project Overview)**

### **1.1. 프로젝트 목표**

서울시 아파트 실거래가 데이터를 기반으로, 특정 시점의 아파트 매매 가격을 가장 정확하게 예측하는 회귀 모델을 개발한다.

### **1.2. 핵심 성공 지표**

- **주요 지표**: 대회 리더보드의 **RMSE(Root Mean Squared Error) 점수**. 이 점수를 최소화하는 것을 목표로 한다.
- **보조 지표**: 모델의 안정성을 확보하기 위한 **K-fold 교차 검증(Cross-Validation)** 과정에서의 평균 RMSE 값.

---

### **2. 데이터 명세 (Data Specification)**

### **2.1. 입력 데이터**

- **`train.csv`**: 2007년부터 2023년까지의 아파트 거래 정보 및 단지 상세 정보. **`target`** 컬럼 포함.
- **`test.csv`**: 예측해야 할 대상 아파트 거래 정보. **`target`** 컬럼 미포함.
- **`sample_submission.csv`**: 최종 예측 결과를 담아 제출할 파일 형식.

### **2.2. 추가 데이터**

- **`subway_feature.csv`**: 서울시 지하철역 위치 정보 (위도, 경도).
- **`bus_feature.csv`**: 서울시 버스 정류장 위치 정보 (X좌표, Y좌표).

---

### **3. 주요 과제 및 해결 전략 (Key Challenges & Strategy)**

### **3.1. [Challenge] 좌표 데이터의 대량 결측치**

`train.csv`의 핵심 위치 정보인 **`좌표X`**, **`좌표Y`**에 약 78%의 결측치가 존재. 이는 위치 기반 피처 엔지니어링에 가장 큰 장애물임.

### **3.2. [Strategy] 지오코딩(Geocoding)을 통한 결측치 보간**

1. **좌표 존재 시**: 기존 `좌표X`, `좌표Y` 값을 그대로 사용.
2. **좌표 부재 시**: `시군구`, `도로명`, `번지` 등 주소 관련 컬럼을 조합하여 **지오코딩 API**에 요청, 반환된 위도/경도 값으로 결측치를 채운다. 이를 통해 모든 데이터가 위치 정보를 갖게 한다.

---

### **4. 상세 실행 계획 (Detailed Execution Plan)**

### **Phase 1: 데이터 전처리 및 정제 (Data Preprocessing & Cleaning)**

- **Step 1.1: 데이터 로드 및 기본 탐색**
    - 5개의 데이터(`train`, `test`, `subway`, `bus`, `submission`)를 로드하고, 각 데이터의 구조와 타입을 파악한다.
- **Step 1.2: 불필요한 컬럼 제거**
    - 모델 성능에 기여하기 어렵거나 정보가 거의 없는 컬럼들을 초기에 제거하여 분석의 효율성을 높인다.
    - **제거 대상**: `해제사유발생일`, `k-135㎡초과`, `k-등록일자`, `단지소개기존clob` (결측률 90% 이상), `k-전화번호`, `k-팩스번호` (고유 ID성 정보) 등.
- **Step 1.3: 결측치 처리 (Imputation)**
    - **좌표 (`좌표X`, `좌표Y`)**: 상기한 **지오코딩 전략**을 최우선으로 실행.
    - **범주형 컬럼 (`k-관리방식`, `k-난방방식` 등)**: **최빈값(Mode)**으로 대체.
    - **수치형 컬럼 (`k-전체세대수`, `주차대수` 등)**: `시군구`별 평균값이나 중앙값 등 통계치를 활용하거나, 다른 변수를 이용한 회귀 예측으로 대체.
- **Step 1.4: 데이터 유효성 검사**
    - **수치형 데이터 검증**: `target`, `전용면적(㎡)` 등 주요 수치 컬럼에 0, 음수 또는 비정상적인 값(outlier)이 있는지 확인.
    - **논리적 데이터 검증**: `계약년월`이 미래 시점으로 되어 있거나, 존재하지 않는 주소 등 논리적 오류를 탐지.
    - **정제 프로세스**: 1차로 자동화된 규칙을 통해 오류를 탐지하고, 이후 EDA(탐색적 데이터 분석)를 통해 수작업으로 데이터를 정밀하게 정제하는 절차를 명시.

### **Phase 2: 피처 엔지니어링 (Feature Engineering)**

**Step 2.1: 지리/위치 기반 피처 생성**

- **교통 접근성**: `가장_가까운_지하철역_거리`, `가장_가까운_버스정류장_거리` 생성.
- **인프라 밀도**: `반경_1km_내_지하철역_수`, `반경_500m_내_버스정류장_수` 생성.
- **지역 내 상대가치**: `구별_대장아파트까지_거리` 생성.
- **핵심지 접근성**: `주요업무지구(강남,여의도)까지_거리`, `한강까지_거리` 생성.

**Step 2.2: 시간 기반 피처 생성**

- **날짜 세분화**: `계약년월`, `계약일`을 이용해 `거래년도`, `거래월`, `분기`, `요일` 피처 생성.
- **아파트 연식**: `계약년월`과 `건축년도`를 조합해 `거래시점_연식` 피처 생성.

**Step 2.3: 단지 물리적 특성 기반 피처 생성**

- **규모/밀도**: `k-전체세대수`, `주차대수` 등을 조합해 `세대당_주차대수` 피처 생성.
- **층수 정규화**: `층` 정보를 활용해 `상대적_층수_비율` 피처 생성.

**Step 2.4: 상호작용 피처 생성**

- **지역별 면적 가치**: `시군구`와 `전용면적(㎡)`을 조합해 지역별 면적의 가중치를 반영.
- **지역별 연식 가치**: `시군구`와 `거래시점_연식`을 조합해 재건축 등 지역별 특수성을 반영.

### **Phase 3: 모델링 및 평가 (Modeling & Evaluation)**

- **Step 3.1: 모델 선정**
    - **주력 모델**: 커뮤니티에서 가장 우수한 성능을 보인 **LightGBM**을 기본 모델로 선정.
    - **추가 실험 모델**: XGBoost, CatBoost 등 다른 트리 기반 부스팅 모델들을 함께 실험. 최종적으로 단일 모델 또는 앙상블(Ensemble) 기법을 고려.
- **Step 3.2: 교차 검증 (Cross-Validation)**
    - 모델의 일반화 성능을 안정적으로 측정하기 위해 **K-Fold 교차 검증 (K=5 또는 10)**을 수행. 각 Fold의 RMSE를 기록하고 평균값을 모니터링.
- **Step 3.3: 하이퍼파라미터 튜닝**
    - `learning_rate`, `n_estimators`, `max_depth` 등 LightGBM의 주요 하이퍼파라미터를 최적화하여 모델 성능을 극대화. (예: Optuna, GridSearchCV)

### **Phase 4: 최종 예측 및 제출 (Final Prediction & Submission)**

- **Step 4.1: 전체 학습 데이터로 모델 재학습**
    - 최적화된 하이퍼파라미터를 사용하여 `train.csv` **전체** 데이터로 최종 모델을 학습.
- **Step 4.2: 제출 파일 생성**
    - 학습된 최종 모델로 `test.csv`의 데이터를 예측하고, `sample_submission.csv` 형식에 맞추어 `target` 값을 채워 최종 제출 파일을 생성.

---

### **5. 가정 및 의존성 (Assumptions & Dependencies)**

- **지오코딩 API**: 주소 정보를 좌표로 변환하기 위한 외부 지오코딩 API(예: 카카오, 네이버, 공공데이터포털)의 사용이 가능하고, 일일 요청량(Quota)이 충분하다고 가정.
- **데이터의미**: 제공된 데이터의 컬럼명은 그 의미를 정확하게 나타낸다고 가정.

---

### **6. 데이터 품질 및 유효성 검증 절차**

- **Step 1.4: 데이터 유효성 검사**
    - 수치형 컬럼(가격, 면적 등)에 음수/0/비정상치 존재 여부 확인
    - 날짜/주소/코드 등 입력값에 논리적 불일치(예: 미래 거래일, 비정상 주소, 잘못된 구/동/아파트명) 검사
    - *“1차 이상치/오류 자동 탐지 후 EDA로 수작업 정제”* 명시

---

### **7. 피처/모델 버전 관리 및 실험 기록**

- **실험 노트/협업 방식 구체화**
    - 각 팀원이 주피터 노트북 단위로 실험 →
        
        실험 로그(노트북/markdown/csv)로 주요 변경점 기록
        
    - 실험별 폴더/브랜치/파일명 표준화 (예: `eda_v1_potg.ipynb`, `feature_engineering_v2.ipynb`)
    - 실험 결과(RMSE, 피처 리스트, 주요 시도/실패사례) 문서화하여 팀 내 리뷰
        
        → “동일 실험 반복/재현성” 확보
        

---

### **8. 코드/결과 제출 규칙 및 관리**

- **코드/데이터/결과 백업 방식 명시**
    - 실험 코드, 생성된 output.csv, 주요 중간 결과(EDA 산출물 등)를
        
        주기적으로 백업(노션, 공유 드라이브, GitHub 등)
        
        → “파일 유실/실험 덮어쓰기” 예방
        
- **제출 파일 검증 루틴**
    - 제출 전 샘플 submission.csv와 포맷(컬럼, 행 수, 타입 등) 일치 여부 자동 체크 스크립트 추가

---

### 9. 프로젝트 폴더 구조

```bash
upstageailab-ml-competition-ml-5/
│
├── 📂 data/                            # 1. 데이터 폴더
│   ├──  raw/                            # 원본 데이터
│   │   ├── train.csv
│   │   ├── test.csv
│   │   ├── subway_feature.csv
│   │   └── bus_feature.csv
│   └── processed/                       # 전처리 및 가공된 데이터
│       └── train_cleaned.csv
│
├── 📂 notebooks/                        # 2. 주피터 노트북 폴더
│   ├── 01_EDA.ipynb                      # 탐색적 데이터 분석
│   ├── 02_Feature_Engineering.ipynb      # 피처 엔지니어링
│   └── 03_Modeling.ipynb                 # 모델링 및 튜닝
│
├── 📂 src/                              # 3. 소스 코드 폴더
│   ├── utils.py                          # 공통 함수 (예: 거리 계산 함수)
│   └── preprocess.py                     # 전처리 스크립트
│
├── 📂 models/                           # 4. 저장된 모델 폴더
│   └── lgbm_v1.pkl
│
├── 📂 submissions/                      # 5. 제출 파일 폴더
│   └── submission_20250709.csv
│
├── 📄 README.md                         # 6. 프로젝트 설명 파일
└── 📄 requirements.txt                  # 7. 파이썬 라이브러리 의존성 파일
```

---

### **각 폴더의 역할**

1. **`data/`**: 모든 데이터 파일을 저장합니다.
    - **`raw/`**: 대회에서 제공받은 원본 파일을 그대로 보관합니다.
    - **`processed/`**: 결측치 처리, 피처 엔지니어링 등 가공을 거친 데이터를 저장합니다.
2. **`notebooks/`**: 데이터 분석 및 모델링 실험을 위한 주피터 노트북을 관리합니다. 파일명에 번호를 붙여 작업 순서를 명확히 하는 것이 좋습니다.
3. **`src/`**: 여러 노트북에서 공통으로 사용되는 함수나 클래스를 `.py` 스크립트 파일로 저장합니다. 코드의 재사용성을 높여줍니다.
4. **`models/`**: 학습이 완료된 모델을 저장합니다. (예: `pickle`, `joblib` 파일)
5. **`submissions/`**: 대회에 제출할 예측 결과 파일을 날짜나 버전별로 관리합니다.
6. **`README.md`**: 프로젝트의 목표, 실행 방법, 팀원 등 전반적인 내용을 기록하는 가장 중요한 문서입니다.
7. **`requirements.txt`**: 프로젝트에 사용된 라이브러리와 그 버전을 명시하여 다른 환경에서도 동일하게 프로젝트를 실행할 수 있도록 합니다.